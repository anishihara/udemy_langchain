{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import openai\n",
    "# import os\n",
    "\n",
    "# openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] MODEL_ID\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  -m, --model-parameters TEXT     A JSON value that specifies extra values\n",
      "                                  that will be passed to the model. The\n",
      "                                  accepted value parsed to a dict, unpacked\n",
      "                                  and passed as-is to the provider class.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "  version   Prints Jupyter-AI version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %ai list [OPTIONS] [PROVIDER_ID]\n",
      "\n",
      "  List language models, optionally scoped to PROVIDER_ID.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "%ai list --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li><li>`bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0`</li></ul> |\n",
       "| `anthropic` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`anthropic:claude-v1`</li><li>`anthropic:claude-v1.0`</li><li>`anthropic:claude-v1.2`</li><li>`anthropic:claude-2`</li><li>`anthropic:claude-2.0`</li><li>`anthropic:claude-instant-v1`</li><li>`anthropic:claude-instant-v1.0`</li><li>`anthropic:claude-instant-v1.2`</li></ul> |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`anthropic-chat:claude-2.0`</li><li>`anthropic-chat:claude-2.1`</li><li>`anthropic-chat:claude-instant-1.2`</li><li>`anthropic-chat:claude-3-opus-20240229`</li><li>`anthropic-chat:claude-3-sonnet-20240229`</li></ul> |\n",
       "| `azure-chat-openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li></ul> |\n",
       "| `gemini` | `GOOGLE_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`gemini:gemini-1.0-pro`</li><li>`gemini:gemini-1.0-pro-001`</li><li>`gemini:gemini-1.0-pro-latest`</li><li>`gemini:gemini-1.0-pro-vision-latest`</li><li>`gemini:gemini-pro`</li><li>`gemini:gemini-pro-vision`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0125`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-turbo-preview`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-0125-preview`</li><li>`openai-chat:gpt-4-1106-preview`</li></ul> |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "| `togetherai` | `TOGETHER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`togetherai:Austism/chronos-hermes-13b`</li><li>`togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2`</li><li>`togetherai:EleutherAI/llemma_7b`</li><li>`togetherai:Gryphe/MythoMax-L2-13b`</li><li>`togetherai:Meta-Llama/Llama-Guard-7b`</li><li>`togetherai:Nexusflow/NexusRaven-V2-13B`</li><li>`togetherai:NousResearch/Nous-Capybara-7B-V1p9`</li><li>`togetherai:NousResearch/Nous-Hermes-2-Yi-34B`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-13b`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-70b`</li></ul> |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable: AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:cohere.command-light-text-v14\n",
       "* bedrock:cohere.command-text-v14\n",
       "* bedrock:meta.llama2-13b-chat-v1\n",
       "* bedrock:meta.llama2-70b-chat-v1\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-v2:1\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "* bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0\n",
       "\n",
       "anthropic\n",
       "Requires environment variable: ANTHROPIC_API_KEY (not set)\n",
       "* anthropic:claude-v1\n",
       "* anthropic:claude-v1.0\n",
       "* anthropic:claude-v1.2\n",
       "* anthropic:claude-2\n",
       "* anthropic:claude-2.0\n",
       "* anthropic:claude-instant-v1\n",
       "* anthropic:claude-instant-v1.0\n",
       "* anthropic:claude-instant-v1.2\n",
       "\n",
       "anthropic-chat\n",
       "Requires environment variable: ANTHROPIC_API_KEY (not set)\n",
       "* anthropic-chat:claude-2.0\n",
       "* anthropic-chat:claude-2.1\n",
       "* anthropic-chat:claude-instant-1.2\n",
       "* anthropic-chat:claude-3-opus-20240229\n",
       "* anthropic-chat:claude-3-sonnet-20240229\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable: COHERE_API_KEY (not set)\n",
       "* cohere:command\n",
       "* cohere:command-nightly\n",
       "* cohere:command-light\n",
       "* cohere:command-light-nightly\n",
       "\n",
       "gemini\n",
       "Requires environment variable: GOOGLE_API_KEY (set)\n",
       "* gemini:gemini-1.0-pro\n",
       "* gemini:gemini-1.0-pro-001\n",
       "* gemini:gemini-1.0-pro-latest\n",
       "* gemini:gemini-1.0-pro-vision-latest\n",
       "* gemini:gemini-pro\n",
       "* gemini:gemini-pro-vision\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "* gpt4all:mistral-7b-openorca.Q4_0\n",
       "* gpt4all:mistral-7b-instruct-v0.1.Q4_0\n",
       "* gpt4all:gpt4all-falcon-q4_0\n",
       "* gpt4all:wizardlm-13b-v1.2.Q4_0\n",
       "* gpt4all:nous-hermes-llama2-13b.Q4_0\n",
       "* gpt4all:gpt4all-13b-snoozy-q4_0\n",
       "* gpt4all:mpt-7b-chat-merges-q4_0\n",
       "* gpt4all:orca-mini-3b-gguf2-q4_0\n",
       "* gpt4all:starcoder-q4_0\n",
       "* gpt4all:rift-coder-v0-7b-q4_0\n",
       "* gpt4all:em_german_mistral_v01.Q4_0\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable: HUGGINGFACEHUB_API_TOKEN (set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-0125\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-1106\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-turbo-preview\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "* openai-chat:gpt-4-0125-preview\n",
       "* openai-chat:gpt-4-1106-preview\n",
       "\n",
       "qianfan\n",
       "Requires environment variables: QIANFAN_AK (not set), QIANFAN_SK (not set)\n",
       "* qianfan:ERNIE-Bot\n",
       "* qianfan:ERNIE-Bot-4\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "togetherai\n",
       "Requires environment variable: TOGETHER_API_KEY (not set)\n",
       "* togetherai:Austism/chronos-hermes-13b\n",
       "* togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2\n",
       "* togetherai:EleutherAI/llemma_7b\n",
       "* togetherai:Gryphe/MythoMax-L2-13b\n",
       "* togetherai:Meta-Llama/Llama-Guard-7b\n",
       "* togetherai:Nexusflow/NexusRaven-V2-13B\n",
       "* togetherai:NousResearch/Nous-Capybara-7B-V1p9\n",
       "* togetherai:NousResearch/Nous-Hermes-2-Yi-34B\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-13b\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-70b\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:davinci-002\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "ernie-bot - qianfan:ERNIE-Bot\n",
       "ernie-bot-4 - qianfan:ERNIE-Bot-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n"
      ],
      "text/plain": [
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Feature   | Lists            | Tuples              | Sets              |\n",
       "|-----------|------------------|---------------------|-------------------|\n",
       "| Mutability| Mutable          | Immutable           | Mutable           |\n",
       "| Order     | Ordered          | Ordered             | Unordered         |\n",
       "| Duplicates| Allows duplicates| Allows duplicates   | Does not allow duplicates |\n",
       "| Syntax    | [ ]              | ( )                 | { }               |\n",
       "| Use case  | When you need to modify the elements in the collection | When you want to store a collection of items that should not change | When you need to perform set operations like union, intersection, difference |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-3.5-turbo\n",
    "lists vs. tuples vs. sets in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To sort a list in Python, you can use the built-in `sorted()` function or the `sort()` method.\n",
       "\n",
       "Here is an example using the `sorted()` function:\n",
       "\n",
       "```python\n",
       "my_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\n",
       "sorted_list = sorted(my_list)\n",
       "print(sorted_list)\n",
       "```\n",
       "\n",
       "Output:\n",
       "```\n",
       "[1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 9]\n",
       "```\n",
       "\n",
       "And here is an example using the `sort()` method to sort the list in place:\n",
       "\n",
       "```python\n",
       "my_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\n",
       "my_list.sort()\n",
       "print(my_list)\n",
       "```\n",
       "\n",
       "Output:\n",
       "```\n",
       "[1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 9]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "How to sort lists in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The `update()` method in Python is used to update the dictionary with elements from another dictionary or from an iterable of key-value pairs. If the key is already present in the dictionary, its value is updated with the new value. If the key is not present, it is added to the dictionary.\n",
       "\n",
       "Example:\n",
       "```python\n",
       "dict1 = {1: 'apple', 2: 'banana'}\n",
       "dict2 = {3: 'cherry', 4: 'date'}\n",
       "\n",
       "dict1.update(dict2)\n",
       "\n",
       "print(dict1)\n",
       "```\n",
       "\n",
       "Output:\n",
       "```\n",
       "{1: 'apple', 2: 'banana', 3: 'cherry', 4: 'date'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "explain dict.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`dict` is a built-in data type in Python that represents a collection of key-value pairs. It is mutable, unordered, and indexed. Keys within a dictionary must be unique and immutable, while values can be of any data type. Dictionaries are enclosed in curly braces `{}`, with each key-value pair separated by a colon `:`. \n",
       "\n",
       "Example:\n",
       "```python\n",
       "my_dict = {'name': 'John', 'age': 25, 'city': 'New York'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gpt-3.5-turbo\n",
    "explain the dict type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:959\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 959\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/httpx/_models.py:761\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 761\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mai\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchatgpt -f code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDefine a function that calculates the factorial of n\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCall the function with 10 as an argument.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/jupyter_ai_magics/magics.py:618\u001b[0m, in \u001b[0;36mAiMagics.ai\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    615\u001b[0m ip \u001b[38;5;241m=\u001b[39m get_ipython()\n\u001b[1;32m    616\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat_map(FormatDict(ip\u001b[38;5;241m.\u001b[39muser_ns))\n\u001b[0;32m--> 618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_ai_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/jupyter_ai_magics/magics.py:559\u001b[0m, in \u001b[0;36mAiMagics.run_ai_cell\u001b[0;34m(self, args, prompt)\u001b[0m\n\u001b[1;32m    556\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat_map(FormatDict(ip\u001b[38;5;241m.\u001b[39muser_ns))\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider\u001b[38;5;241m.\u001b[39mis_chat_provider:\n\u001b[0;32m--> 559\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;66;03m# generate output from model via provider\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     result \u001b[38;5;241m=\u001b[39m provider\u001b[38;5;241m.\u001b[39mgenerate([prompt])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    407\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    409\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    413\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 398\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:577\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:441\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    436\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 441\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:356\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:1011\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1007\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1014\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1019\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Define a function that calculates the factorial of n\n",
    "Call the function with 10 as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3628800\n"
     ]
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "print(factorial(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Change the function to be a recursive one\n",
    "call the function with 8 as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "def recursive_function(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n + recursive_function(n-1)\n",
    "\n",
    "print(recursive_function(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "def calculate_area(length, width):\n",
       "    \"\"\"\n",
       "    This function calculates the area of a rectangle given its length and width.\n",
       "\n",
       "    Parameters:\n",
       "    length (int or float): The length of the rectangle.\n",
       "    width (int or float): The width of the rectangle.\n",
       "\n",
       "    Returns:\n",
       "    float: The calculated area of the rectangle.\n",
       "    \"\"\"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Can you write a docstring for this function explaining what the function does and the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchOption",
     "evalue": "No such option: -r",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/parser.py:514\u001b[0m, in \u001b[0;36mOptionParser._process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_long_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_long_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoSuchOption:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# At this point the long option matching failed, and we need\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;66;03m# to try with short options.  However there is a special rule\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;66;03m# short option code and will instead raise the no option\u001b[39;00m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;66;03m# error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/parser.py:398\u001b[0m, in \u001b[0;36mOptionParser._match_long_opt\u001b[0;34m(self, opt, explicit_value, state)\u001b[0m\n\u001b[1;32m    397\u001b[0m     possibilities \u001b[38;5;241m=\u001b[39m get_close_matches(opt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_long_opt)\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchOption(opt, possibilities\u001b[38;5;241m=\u001b[39mpossibilities, ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\n\u001b[1;32m    400\u001b[0m option \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_long_opt[opt]\n",
      "\u001b[0;31mNoSuchOption\u001b[0m: No such option: -r",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mai\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchatgpt -r\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclear the histor\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/jupyter_ai_magics/magics.py:573\u001b[0m, in \u001b[0;36mAiMagics.ai\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    571\u001b[0m raw_args \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell:\n\u001b[0;32m--> 573\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mcell_magic_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%%\u001b[39;49;00m\u001b[38;5;124;43mai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandalone_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     args \u001b[38;5;241m=\u001b[39m line_magic_parser(raw_args, prog_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, standalone_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/core.py:1157\u001b[0m, in \u001b[0;36mBaseCommand.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/core.py:1077\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1077\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m   1078\u001b[0m             rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(ctx)\n\u001b[1;32m   1079\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m standalone_mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/core.py:943\u001b[0m, in \u001b[0;36mBaseCommand.make_context\u001b[0;34m(self, info_name, args, parent, **extra)\u001b[0m\n\u001b[1;32m    938\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_class(\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m, info_name\u001b[38;5;241m=\u001b[39minfo_name, parent\u001b[38;5;241m=\u001b[39mparent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    940\u001b[0m )\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mscope(cleanup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/core.py:1405\u001b[0m, in \u001b[0;36mCommand.parse_args\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m   1402\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mexit()\n\u001b[1;32m   1404\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_parser(ctx)\n\u001b[0;32m-> 1405\u001b[0m opts, args, param_order \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m iter_params_for_processing(param_order, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(ctx)):\n\u001b[1;32m   1408\u001b[0m     value, args \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mhandle_parse_result(ctx, opts, args)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/parser.py:337\u001b[0m, in \u001b[0;36mOptionParser.parse_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    335\u001b[0m state \u001b[38;5;241m=\u001b[39m ParsingState(args)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_args_for_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_args_for_args(state)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UsageError:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/parser.py:364\u001b[0m, in \u001b[0;36mOptionParser._process_args_for_options\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt_prefixes \u001b[38;5;129;01mand\u001b[39;00m arglen \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_opts\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_interspersed_args:\n\u001b[1;32m    366\u001b[0m     state\u001b[38;5;241m.\u001b[39mlargs\u001b[38;5;241m.\u001b[39mappend(arg)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/parser.py:523\u001b[0m, in \u001b[0;36mOptionParser._process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NoSuchOption:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# At this point the long option matching failed, and we need\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;66;03m# to try with short options.  However there is a special rule\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;66;03m# short option code and will instead raise the no option\u001b[39;00m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;66;03m# error.\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opt_prefixes:\n\u001b[0;32m--> 523\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_short_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_unknown_options:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/click/parser.py:436\u001b[0m, in \u001b[0;36mOptionParser._match_short_opt\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    434\u001b[0m         unknown_options\u001b[38;5;241m.\u001b[39mappend(ch)\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchOption(opt, ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m option\u001b[38;5;241m.\u001b[39mtakes_value:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Any characters left in arg?  Pretend they're the\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# next arg, and stop consuming characters of arg.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n",
      "\u001b[0;31mNoSuchOption\u001b[0m: No such option: -r"
     ]
    }
   ],
   "source": [
    "%%ai chatgpt -r\n",
    "clear the histor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "a, b = 10, '4'\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "The error is caused by trying to add an integer and a string together, which is not a supported operation in Python. To fix this error, you can either convert the integer to a string or the string to an integer before performing the addition.\n",
       "\n",
       "Corrected code:\n",
       "a, b = 10, '4'\n",
       "a + int(b)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "explain the following python error: {Err[23]}\n",
    "give me the correct code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Add the correct code for {Err[23]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 10, '4'\n",
    "a + int(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (632076689.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[30], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    s1 = 'Hello Python\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Hello Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The error \"SyntaxError: unterminated string literal\" occurs when a string in the code is not properly closed, causing Python to consider the string as continuing onto the next line. \n",
       "\n",
       "In this specific case, the error is detected at line 1 of Cell In[30] where the string 'Hello Python is not closed with a single quote. The missing single quote at the end of the string causes Python to interpret the string as being unterminated. \n",
       "\n",
       "To fix this error, the string should be properly closed with a single quote like this:\n",
       "```python\n",
       "s1 = 'Hello Python'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai error chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [n**2 for n in range(10)]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "x = [n**2 for n in range(10)]\n",
       "x\n",
       "```\n",
       "\n",
       "This code creates a list `x` containing the square of each number in the range from 0 to 9. The output will be:\n",
       "```\n",
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Please explain this code: {In[33]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = [0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91, 105, 120,136, 153, 171, 190, 210]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 10,\n",
       " 15,\n",
       " 21,\n",
       " 28,\n",
       " 36,\n",
       " 45,\n",
       " 55,\n",
       " 66,\n",
       " 78,\n",
       " 91,\n",
       " 105,\n",
       " 120,\n",
       " 136,\n",
       " 153,\n",
       " 171,\n",
       " 190,\n",
       " 210]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def number_sequence(n):\n",
       "    sequence = [int(i*(i+1)/2) for i in range(n)]\n",
       "    return sequence\n",
       "\n",
       "print(number_sequence(21))\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Define a function that takes an argument and return this sequence of numbers: {Out[37]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91, 105, 120, 136, 153, 171, 190, 210, 231, 253, 276, 300]\n"
     ]
    }
   ],
   "source": [
    "def number_sequence(n):\n",
    "    sequence = [int(i*(i+1)/2) for i in range(n)]\n",
    "    return sequence\n",
    "\n",
    "print(number_sequence(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN']= 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<jupyter_ai_magics.magics.Base64Image at 0x7fd144a58b50>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "jupyter_ai": {
       "model_id": "stabilityai/stable-diffusion-2-1",
       "provider_id": "huggingface_hub"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai huggingface_hub:stabilityai/stable-diffusion-2-1 --format image\n",
    "dystopian fantasy landscape, cyberpunk style, flying objects, red moon in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
